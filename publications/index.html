<!DOCTYPE HTML PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Mathieu Blondel // Publications</title>
<link rel="stylesheet" href="../style.css" type="text/css" media="screen">
</head>

<body>

<div id="topbar">
  <div id="header">
    <h1>Mathieu Blondel</h1>
  </div>
</div>

<div id="navigation">
  <p>
  <a href="../">Home</a> /
  <a href="." class="active">Publications</a> /
  <a href="../talks/">Talks</a> /
  <a href="../code/">Software</a> /
  <a href="../data/">Data</a> 
  </p>
</div>

<div id="main">

<h2>Selected publications</h2>

<p>For a full list, see my Google scholar <a href="http://scholar.google.com/citations?user=C0EKzrUAAAAJ">profile</a>.</p>

<ul class="pub">

<li>
Smooth and Sparse Optimal Transport. <br />
<u>Mathieu Blondel</u>, Vivien Seguy, Antoine Rolet.<br />
In Proceedings of Artificial Intelligence and Statistics (<strong>AISTATS</strong>), April 2018. <br />
<a href="https://arxiv.org/abs/1710.06276">arXiv</a> / 
<a href="https://github.com/mblondel/smooth-ot">Code</a>
</li>

<li>
A Regularized Framework for Sparse and Structured Neural Attention. <br />
Vlad Niculae, <u>Mathieu Blondel</u>.<br />
In Proceedings of Neural Information Processing Systems (<strong>NIPS</strong>), December 2017. <br />
<a href="https://arxiv.org/abs/1705.07704">arXiv</a> / 
<a href="https://github.com/vene/sparse-structured-attention">Code</a>
</li>

<li>
Multi-output Polynomial Networks and Factorization Machines. <br />
<u>Mathieu Blondel</u>, Vlad Niculae, Takuma Otsuka, Naonori Ueda.<br />
In Proceedings of Neural Information Processing Systems (<strong>NIPS</strong>), December 2017. <br />
<a href="https://arxiv.org/abs/1705.07603">arXiv</a> <br />
</li>

<li>
Soft-DTW: a Differentiable Loss Function for Time-Series. <br />
Marco Cuturi, <u>Mathieu Blondel</u>.<br />
In Proceedings of International Conference on Machine Learning (<strong>ICML</strong>), August 2017. <br />
<a href="mcuturi-mblondel-icml2017.pdf">PDF</a> / 
<a href="https://github.com/mblondel/soft-dtw">Code</a>
</li>

<li>
Higher-order Factorization Machines. <br />
<u>Mathieu Blondel</u>, Akinori Fujino, Naonori Ueda, Masakazu Ishihata. <br />
In Proceedings of Neural Information Processing Systems (<strong>NIPS</strong>), December 2016. <br />
<a href="http://arxiv.org/abs/1607.07195">arXiv</a>
</li>

<li>
Polynomial Networks and Factorization Machines: New Insights and Efficient Training Algorithms. <br />
<u>Mathieu Blondel</u>, Masakazu Ishihata, Akinori Fujino, Naonori Ueda. <br />
In Proceedings of International Conference on Machine Learning (<strong>ICML</strong>), September 2016. <br />
<a href="mblondel-icml2016.pdf">PDF</a> <br />
Open-source <a href="https://github.com/scikit-learn-contrib/polylearn">implementation</a> by <a href="http://vene.ro/">Vlad Niculae</a>
</li>

<li>
Convex Factorization Machines. <br />
<u>Mathieu Blondel</u>, Akinori Fujino, Naonori Ueda. <br />
In Proceedings of European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (<strong>ECML PKDD</strong>), September 2015. <br />
<a href="mblondel-ecmlpkdd2015.pdf">PDF</a> / <a href="../talks/mblondel-cambridge-2015-09.pdf">Slides</a> <br />
Open-source <a href="https://gist.github.com/vene/d0fa89c17de961a18f7b">implementation</a> by <a href="http://vene.ro/">Vlad Niculae</a>
</li>

<li>
Large-scale Multiclass Support Vector Machine Training via Euclidean Projection onto the Simplex. <br />
<u>Mathieu Blondel</u>, Akinori Fujino, Naonori Ueda. <br />
In Proceedings of the 22nd International Conference on Pattern Recognition (<strong>ICPR</strong>), August 2014.<br />
<a href="mblondel-icpr2014.pdf">PDF</a> /
<a href="https://gist.github.com/mblondel/97cffbea574a5890f0d7">Code</a>
</li>

<li>
Online Passive-Aggressive Algorithms for Non-Negative Matrix Factorization and Completion. <br />
<u>Mathieu Blondel</u>, Yotaro Kubo, Naonori Ueda.  <br /> 
In Proceedings of the 17th International Conference on Artifical Intelligence and Statistics (<strong>AISTATS</strong>), April 2014. <br />
<a href="mblondel-aistats2014.pdf">PDF</a> / <a href="mblondel-aistats2014-supp.pdf">Supplementary material</a> 

<li>Block Coordinate Descent Algorithms for Large-scale Sparse Multiclass 
Classification. <br />
<u>Mathieu Blondel</u>, Kazuhiro Seki, Kuniaki Uehara. <br />
<strong>Machine Learning</strong>, May 2013. The final publication is available <a href="http://link.springer.com/article/10.1007%2Fs10994-013-5367-2">here</a>.<br/>
Open-science honorable mention at ECML PKDD 2013. <br />
<a href="mblondel-mlj2013.pdf">PDF</a> / <a href="https://github.com/scikit-learn-contrib/lightning">Code</a> / <a href="../data/">Data</a> 
</li>

</ul>

<h2>Machine learning software</h2>

<ul class="pub">
<li>Scikit-learn: Machine Learning in Python. <br />
Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand 
Thirion, Olivier Grisel, <u>Mathieu Blondel</u>, Peter Prettenhofer, Ron Weiss, 
Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu 
Brucher, Matthieu Perrot, Édouard Duchesnay. <br />
Journal of Machine Learning Research (<strong>JMLR</strong>), volume 12, pp. 2825−2830, 2011. <br />
<a 
href="http://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf">PDF</a> / <a 
href="http://scikit-learn.org">Homepage</a>
</li>

<li>API design for machine learning software: experiences from the scikit-learn project <br />
Lars Buitinck, Gilles Louppe, <u>Mathieu Blondel</u>, Fabian Pedregosa, Andreas
Müller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort,
Jaques Grobler, Robert Layton, Jake Vanderplas, Arnaud Joly, Brian Holt, 
Gaël Varoquaux. <br />
<strong>ECML PKDD Workshop</strong>:
Languages for Data Mining and Machine Learning, September 2013. <br />
<a href="lbuitinck-ecmlpkdd2013.pdf">PDF</a>
</li>
</ul>

</div>

<div id="footer">
Copyright 2010-Present Mathieu Blondel
</div>

</body>
</html>
